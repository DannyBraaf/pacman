# This is a basic workflow to help you get started with Actions

name: CI/CD Deployment Production

# Controls when the workflow will run
on:


  pull_request_target:
    types:
      - closed
    branches: [ master ]


  workflow_dispatch:


jobs:

  ## Open a Trakcing/Documentation issue linked in the Github Project for Feedback loop
  Open-Tracking-Issue:
       runs-on: dynatracedemo
       environment:
          name: production
          url: ${{ steps.set_gh_url.outputs.gh_project_url }} 
       outputs:
            output1: ${{ steps.create-issue.outputs.number }}
            output2: ${{ steps.set-version.outputs.build_version }}
            output3: ${{ steps.set_ip.outputs.publicip }}
            DT_PROD_DB_ID: ${{ steps.get_variables_db.outputs.dt_prod_db_id }}
            DT_MZ_ID: ${{ steps.set_mgmt_zone.outputs.dt_mz_id}}
            GITHUB_PROJECT_URL: ${{ steps.set_gh_url.outputs.gh_project_url }}
            DT_URL: ${{ steps.set_dt_url.outputs.dt_url }}
            DOCKER_TAG: ${{ steps.set_docker_tag.outputs.docker_tag}}
            DT_PPROD_DB_ID: ${{ steps.get_variables_db_pre.outputs.dt_pprod_db_id }}
            
            
       steps:
       - name: Set Release Version Variablea
         id: set_ip
         run: |
               export publicip=$(curl http://checkip.amazonaws.com)               
               echo "::set-output name=publicip::$publicip"
               
       - name: Set Pre Eval Dashboard Id Variable
         id: get_variables_db_pre
         run: |
              export dt_pprod_db_id=$(curl -X GET ${{ secrets.DT_API_URL }}/config/v1/dashboards -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}' | jq -r '.[] | map(select(.name == "KQG;project=deployment-gates;stage=production;service=tnt-acer-svc"))| .[0].id')
              echo $dt_pprod_db_id
              echo "::set-output name=dt_pprod_db_id::$dt_pprod_db_id"
                     
       - name: Set Dashboard Id Variable
         id: get_variables_db
         run: |
              export dt_prod_db_id=$(curl -X GET ${{ secrets.DT_API_URL }}/config/v1/dashboards -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}' | jq -r '.[] | map(select(.name == "KQG;project=slo-evaluation;stage=production;service=tnt-acer-svc"))| .[0].id')
              echo $dt_prod_db_id
              echo "::set-output name=dt_prod_db_id::$dt_prod_db_id"
    
       - name: Set Management zone Id Variable
         id: set_mgmt_zone
         run: |
              export dt_mz_id=$(curl -L -X GET '${{ secrets.DT_API_URL }}/config/v1/managementZones' -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}' | jq -r '.[] | map(select(.name == "Tenant: tnt-acer-svc")) | .[0].id')
              echo $dt_mz_id
              echo "::set-output name=dt_mz_id::$dt_mz_id"
              
       - name: Set Github Url
         id: set_gh_url
         run: |
              export gh_project_url=$(cat /home/ec2-user/ghprojurl)
              echo "::set-output name=gh_project_url::$gh_project_url"
              
       - name: Set DT Url Variable
         id: set_dt_url
         run: |
              export dt_url=$(cat /home/ec2-user/dturl)
              echo "::set-output name=dt_url::$dt_url"
    
       - name: Set Docker Tag Variable
         id: set_docker_tag
         run: |
              export dt_url=$(cat /home/ec2-user/dockertag)
              echo "::set-output name=docker_tag::$dt_url"
                     
       - id: set-version
         run: |
              export build_version=$(cat /home/ec2-user/release)
              echo $build_version
              echo "::set-output name=build_version::$build_version"
                
        
       - name: Create Issue Action
         id: create-issue
         uses: dacbd/create-issue-action@main
         with:
            title: Production Release
            token: ${{secrets.WORKFLOW_TOKEN}}
            assignees: ${{github.actor}}
            labels: documentation, Build ${{ steps.set-version.outputs.build_version }}
            body: <a href="${{ github.SERVER_URL }}/${{ github.REPOSITORY }}/actions/runs/${{ github.RUN_ID }}"> Workflow Monitor </a> <br> <a href="${{ steps.set_dt_url.outputs.dt_url }}/#dashboard;id=${{ steps.get_variables_db.outputs.dt_prod_db_id }};gf=${{ steps.set_mgmt_zone.outputs.dt_mz_id}};gtf=-10m"> Dynatrace Dev validation Dashboard  </a> <br> <a href="${{secrets.DT_CA_URL}}/bridge/project/slo-evaluation/sequence"> Dynatrace Cloud automation  </a>

       - run: 'echo Created issue number ${{ steps.create-issue.outputs.number }}'   
 
       - name: Create or Update Project Card
         uses: peter-evans/create-or-update-project-card@v2
         with:
            project-name: Simplenodeservice
            column-name: üßë‚Äçüíª In progress
            issue-number: ${{ steps.create-issue.outputs.number }}
            
  ## trigger pre-deployment slo-validation to make sure the environment is ready to be deployed to 
  Dynatrace-Pre-Deployment-validation:
      runs-on: dynatracedemo
      environment:
        name: production
        url: ${{needs.Open-Tracking-Issue.outputs.DT_URL }}/#dashboard;gtf=${{ env.startdate }}+02:00%20to%20${{ env.enddate }}+02:00;gf=${{needs.Open-Tracking-Issue.outputs.DT_MZ_ID}};id=${{needs.Open-Tracking-Issue.outputs.DT_PPROD_DB_ID}}
      outputs:
              output1: ${{ steps.passvariable.outputs.DG_validation_SCORE }}
      needs: [Open-Tracking-Issue ]
      steps:
      - uses: actions/checkout@v2
        with:
           ref: 'master'
      - name: trigger-dynatrace-slo-validation
        env:
          ca_token: ${{ secrets.CA_TOKEN }} 
          DG_validation_SCORE: $DG_validation_SCORE
        run: |
           trigger_validation()
                {
                curl -X POST "${{secrets.DT_CA_URL}}/api/controlPlane/v1/project/deployment-gates/stage/production/service/tnt-acer-svc/evaluation" \
                -H "accept: application/json; charset=utf-8" \
                -H "x-token: $ca_token" \
                -H "Content-Type: application/json; charset=utf-8" \
                -d "{\"timeframe\": \"5m\", \"labels\":{\"buildId\":\"${{ needs.Open-Tracking-Issue.outputs.output2 }}\", \"evaltime\":\"$(date +%s%3N)\"}}" \
                -o "keptnContext.json"
                keptnContext=$(cat keptnContext.json | jq -r '.keptnContext')
                echo "Keptn context: $keptnContext"
                echo $keptnContext
                }

           DG_validation_SCOREX=0
           while [[ $DG_validation_SCOREX -le 89 ]]
              do     
                  trigger_validation
                  DG_validation_RESULT=""
                  DG_validation_SCORE=""
                  DG_validation_SCORE=$(curl -X GET "${{secrets.DT_CA_URL}}/api/mongodb-datastore/event?keptnContext=$keptnContext&&type=sh.keptn.event.evaluation.finished" \
                      -H "accept: application/json; charset=utf-8" \
                      -H "x-token: $ca_token" | jq -r '.events[0].data.evaluation.score')
                  echo $DG_validation_SCORE
                  while [[ "$DG_validation_SCORE" == null ]]
                  do
                      DG_validation_SCORE=$(curl -X GET "${{secrets.DT_CA_URL}}/api/mongodb-datastore/event?keptnContext=$keptnContext&&type=sh.keptn.event.evaluation.finished" \
                          -H "accept: application/json; charset=utf-8" \
                          -H "x-token: $ca_token" | jq  '.events[0].data.evaluation.score')
                      sleep 10
                  done
                  startdate=$(date -d "$TIME + 125min" +"%Y-%m-%dT%H:%M:%S")
                  enddate=$(date -d "$TIME + 120min" +"%Y-%m-%dT%H:%M:%S")
                  export DG_validation_SCOREX=$DG_validation_SCORE
                  echo $DG_validation_SCOREX
                  echo $DG_validation_SCORE
                  echo "DG_validation_SCORE=$DG_validation_SCORE" >> "$GITHUB_ENV"
                  echo "kepncontext=$keptnContext" >> "$GITHUB_ENV"
                  echo "startdate=$startdate" >> "$GITHUB_ENV"
                  echo "enddate=$enddate" >> "$GITHUB_ENV" 
              done
           sleep 50
      - id: passvariable
        run: |
             echo "::set-output name=DG_validation_SCORE::${{ env.DG_validation_SCORE }}"
             echo "::set-output name=kepncontext::${{ env.kepncontext }}"
             echo "::set-output name=startdate::${{ env.startdate }}"
             echo "::set-output name=enddate::${{ env.enddate }}"
        if: "${{ steps.passvariable.outputs.DG_validation_SCORE }} >= 90 }}"
      - name: Create comment
        uses: peter-evans/create-or-update-comment@v2
        with:
            issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
            body: |
                   Pre Deployment Slo validation has Passed with a Score of ${{ steps.passvariable.outputs.DG_validation_SCORE }}% <a href="${{needs.Open-Tracking-Issue.outputs.DT_URL }}/#dashboard;gtf=${{ env.startdate }}+02:00%20to%20${{ env.enddate }}+02:00;gf=${{needs.Open-Tracking-Issue.outputs.DT_MZ_ID}};id=${{needs.Open-Tracking-Issue.outputs.DT_PROD_DB_ID}}"> Dynatrace Deployment Readyness Slo Dashboard </a>


  ## Deploy New Build Container to Kubernetes CLuster 
  ## Not Best practice as we use "Kubectl Replace", which deletes the current deployment and deploys the new build
  ## In a real live scenario you would use the Rolling Update function of Kubernetes, but that would make the deployment task run for a long time        
  Deploy-Application:
      runs-on: dynatracedemo
      environment:
       name: production
       url: "http://${{ needs.Open-Tracking-Issue.outputs.output3 }}:8002/"
      needs: [Dynatrace-Pre-Deployment-validation, Open-Tracking-Issue]
      if: "${{ needs.Dynatrace-Pre-Deployment-validation.outputs.output1 > 89 }}" 
      steps:
      - name: Deploy Application to Production NS
        env:
          builid: ${{ github.run_number }}
        run: |
          export build_version=${{ needs.Open-Tracking-Issue.outputs.output2 }}
          export ct_version=${{ needs.Open-Tracking-Issue.outputs.output2 }}
          export dockertag="${{needs.Open-Tracking-Issue.outputs.DOCKER_TAG}}"
          rm -f /home/ec2-user/rollback_prod.yaml || true 
          cp final_prod.yml /home/ec2-user/rollback_prod.yaml  || true  
          rm -f final_prod.yml temp_prod.yml
          ( echo "cat <<EOF >final_prod.yml";
            cat kubernetes/env/prod.yaml;
            echo "EOF";
          ) >temp_prod.yml
          . temp_prod.yml
          cat final_prod.yml
          export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
          echo "$(cat final_prod.yml)"
          kubectl replace -f final_prod.yml --force
          kubectl wait --for=condition=available --timeout=120s --all deployments --namespace simplenodeservice-prod
          
      - name: set var
        run: |
          export cmtmsgt=$(cat /home/ec2-user/commitmsg)
          echo "cmtmsgt=$cmtmsgt" >> "$GITHUB_ENV"
          
      - name: Initial Deployment
        if: "contains(env.cmtmsgt, 'first')"
        run: |
             sleep 500

    
  ## Trigger Dynatrace Slo validation to make sure Slos are still met in production
  Dynatrace-Slo-validation:

      runs-on: dynatracedemo
      environment:
        name: production
        url: ${{needs.Open-Tracking-Issue.outputs.DT_URL }}/#dashboard;gtf=${{ env.startdate }}+02:00%20to%20${{ env.enddate }}+02:00;gf=${{needs.Open-Tracking-Issue.outputs.DT_MZ_ID}};id=${{needs.Open-Tracking-Issue.outputs.DT_PROD_DB_ID}}
      outputs:
              output1: ${{ steps.passvariable.outputs.validation_SCORE }}
              output2: ${{ steps.passvariable.outputs.keptncontext }}
              output3: ${{ steps.passvariable.outputs.startdate }}
              output4: ${{ steps.passvariable.outputs.enddate }}
      needs: [Deploy-Application, Open-Tracking-Issue]
      steps:
      - name: trigger-dynatrace-slo-validation 
        env:
          ca_token: ${{ secrets.CA_TOKEN }} 
          validation_SCORE: $validation_SCORE
        run: |
          trigger_validation()
          {
          export build_version=$(cat /home/ec2-user/release)
          curl -X POST "${{secrets.DT_CA_URL}}/api/controlPlane/v1/project/slo-evaluation/stage/production/service/tnt-acer-svc/evaluation" \
          -H "accept: application/json; charset=utf-8" \
          -H "x-token: $ca_token" \
          -H "Content-Type: application/json; charset=utf-8" \
          -d "{\"timeframe\": \"5m\", \"labels\":{\"buildId\":\"${{ needs.Open-Tracking-Issue.outputs.output2 }}\", \"evaltime\":\"$(date +%s%3N)\"}}" \
          -o "keptnContext.json"
          keptnContext=$(cat keptnContext.json | jq -r '.keptnContext')
          echo "Keptn context: $keptnContext"
          echo $keptnContext
          }
          trigger_validation

          validation_RESULT=""
          validation_SCORE=""
          validation_SCORE=$(curl -X GET "${{secrets.DT_CA_URL}}/api/mongodb-datastore/event?keptnContext=$keptnContext&&type=sh.keptn.event.evaluation.finished" \
              -H "accept: application/json; charset=utf-8" \
              -H "x-token: $ca_token" | jq -r '.events[0].data.evaluation.score')
          echo $validation_SCORE
          while [[ "$validation_SCORE" == null ]]
          do
              validation_SCORE=$(curl -X GET "${{secrets.DT_CA_URL}}/api/mongodb-datastore/event?keptnContext=$keptnContext&&type=sh.keptn.event.evaluation.finished" \
                  -H "accept: application/json; charset=utf-8" \
                  -H "x-token: $ca_token" | jq  '.events[0].data.evaluation.score')
              sleep 10


          done
          startdate=$(date -d "$TIME + 125min" +"%Y-%m-%dT%H:%M:%S")
          enddate=$(date -d "$TIME + 120min" +"%Y-%m-%dT%H:%M:%S")
          echo $validation_SCORE
          echo "validation_SCORE=$validation_SCORE" >> "$GITHUB_ENV"
          echo $keptnContext
          echo "kepncontext=$keptnContext" >> "$GITHUB_ENV"
          echo "startdate=$startdate" >> "$GITHUB_ENV"
          echo "enddate=$enddate" >> "$GITHUB_ENV"
      
      - id: passvariable
        run: |
            echo "::set-output name=validation_SCORE::${{ env.validation_SCORE }}"
            echo "::set-output name=kepncontext::${{ env.kepncontext }}"
            echo "::set-output name=startdate::${{ env.startdate }}"
            echo "::set-output name=enddate::${{ env.enddate }}"
            
      - run: sleep 50
            
        if: "${{ steps.passvariable.outputs.validation_SCORE >= 90 }}"
      - name: Create comment
        uses: peter-evans/create-or-update-comment@v2
        with:
            issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
            body: |
                  Simplenodeservice was successfully deployed to Production <a href="http://${{ needs.Open-Tracking-Issue.outputs.output3 }}:8002/"> Simplenodeservice Production </a> <br> Slo validation has Passed with a Score of ${{ steps.passvariable.outputs.validation_SCORE }}% <a href="${{needs.Open-Tracking-Issue.outputs.DT_URL }}/#dashboard;gtf=${{ env.startdate }}+02:00%20to%20${{ env.enddate }}+02:00;gf=${{needs.Open-Tracking-Issue.outputs.DT_MZ_ID}};id=${{needs.Open-Tracking-Issue.outputs.DT_PROD_DB_ID}}"> Dynatrace Slo Dashboard </a>

        if: "${{ steps.passvariable.outputs.validation_SCORE >= 90 }}"
      - name: Create or Update Project Card
        uses: peter-evans/create-or-update-project-card@v2
        with:
            project-name: Simplenodeservice
            column-name: üö¢ Shipped
            issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
  
        if: "${{ steps.passvariable.outputs.validation_SCORE >= 90 }}"    
      - name: Create Label
        uses: andymckay/labeler@1.0.4
        with:
              # The GitHub token
              repo-token: ${{secrets.WORKFLOW_TOKEN}}
              # Labels to add to an issue, seperated by commas.
              add-labels: "Slo validation Passed"
              # An issue number or PR number or project card number. Optional, if not specified, will use the one available in github event `github.event.pull_request` or `github.event.issue`
              issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
  
  
  
  
      - name: Close Issue
        uses: peter-evans/close-issue@v2
        with:
            issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
            comment: Auto-closing issue
            
      - name: get-group-id
        id: get-group-id
        env:
          ca_token: ${{ secrets.CA_TOKEN }} 
          Validation_SCORE: $Validation_SCORE
        run: |
          export entityId1=$(curl -X GET '${{ secrets.DT_API_URL }}/v2/entities?entitySelector=type(%22PROCESS_GROUP_INSTANCE%22),mzName(%22Tenant:%20tnt-acer-svc-prod%22),tag(%22\[Environment\]DT_RELEASE_BUILD_VERSION:${{ needs.Open-Tracking-Issue.outputs.output2 }}%22)' -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}'| jq -r '.entities[0].entityId')
          echo $entityId1
          export entityId2=$(curl -X GET '${{ secrets.DT_API_URL }}/v2/entities?entitySelector=type(%22PROCESS_GROUP_INSTANCE%22),mzName(%22Tenant:%20tnt-acer-svc-prod%22),tag(%22\[Environment\]DT_RELEASE_BUILD_VERSION:${{ needs.Open-Tracking-Issue.outputs.output2 }}%22)' -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}'| jq -r '.entities[1].entityId')
          echo $entityId2
          echo "::set-output name=entityId1::$entityId1"
          echo "::set-output name=entityId2::$entityId2"
          
      - name: send-deployment-event
        id: senddeploymentevent
        env:
          ca_token: ${{ secrets.CA_TOKEN }} 
          Validation_SCORE: $Validation_SCORE
        run: |
          trigger_send_event()
          {
          curl -X POST '${{ secrets.DT_API_URL }}/v1/events' \
          -H 'accept: application/json' \
          -H 'Authorization: Api-Token ${{ secrets.DT_API_TOKEN }}' \
          -H 'Content-Type: application/json' \
          -d '{ "eventType": "CUSTOM_DEPLOYMENT", "attachRules": { "entityIds": [ "${{ steps.get-group-id.outputs.entityId1 }}", "${{ steps.get-group-id.outputs.entityId2 }}" ], "tagRule": [ { "meTypes": [ "PROCESS_GROUP_INSTANCE" ], "tags": [ { "context": "CONTEXTLESS", "key": "Stage", "value": "production" } ] } ] }, "deploymentName": "Simplenodeservice", "deploymentVersion": ${{ github.run_number }}, "deploymentProject": "Simplenodeservice", "ciBackLink": "${{ github.SERVER_URL }}/${{ github.REPOSITORY }}/actions/runs/${{ github.RUN_ID }}", "source": "GitHub", "customProperties": { "Commits": "${{ github.SHA }}", "GitHub_Repository": "${{ github.REPOSITORY }}", "GitHub Repository Url": "${{ github.REPOSITORY }}", "GitHub Project Url": "${{env.GITHUB_PROJECT_URL}}", "Github Tracking issue": "${{ needs.Open-Tracking-Issue.outputs.output1 }}", "GitHub Tracking Issue Url": "${{ github.SERVER_URL }}/${{ github.REPOSITORY }}/issues/${{ needs.Open-Tracking-Issue.outputs.output1 }}", "Release Validation Score": "${{ steps.passvariable.outputs.Validation_SCORE }}", "GitHub Actor": "${{ github.ACTOR }}"}}'
          }
          trigger_send_event          
  


  ## if validation fails create a new issue with the Results     
  On-Fail-Create-Issue:
         runs-on: dynatracedemo
         needs: [Dynatrace-Slo-validation, Open-Tracking-Issue]
         if: "${{ needs.Dynatrace-Slo-validation.outputs.output1 < 90 }}"
         steps:
         - name: Create Issue Action
           id: create-issue2
           uses: dacbd/create-issue-action@main
           with:
              title: Production Slo validation Failed with ${{ needs.Dynatrace-slo-validation.outputs.output1 }} %
              token: ${{secrets.WORKFLOW_TOKEN}}
              assignees: ${{github.actor}}
              labels: Slo validation Failed, Build ${{ needs.Dynatrace-slo-validation.outputs.output1 }}
              body: Slo validation Failed <a href="${{secrets.DT_CA_URL}}/bridge/project/slo-evaluation/service/tnt-acer-svc/context/${{ needs.Dynatrace-slo-evaluation.outputs.output2 }}"> Cloud Automation </a> <br> <a href="${{needs.Open-Tracking-Issue.outputs.DT_URL }}/#dashboard;gtf=${{ env.startdate }}+02:00%20to%20${{ env.enddate }}+02:00;gf=${{needs.Open-Tracking-Issue.outputs.DT_MZ_ID}};id=${{needs.Open-Tracking-Issue.outputs.DT_PROD_DB_ID}}"> Dynatrace Slo Dashboard </a>
           env:
             validation_SCORE: ${{env.validation_SCORE}}
             
             
         - name: Create or Update Project Card
           uses: peter-evans/create-or-update-project-card@v2
           with:
              project-name: Simplenodeservice
              column-name: üßë‚Äçüíª In progress
              issue-number: ${{ steps.create-issue2.outputs.number }}
              
              
         - name: Create Label
           uses: andymckay/labeler@1.0.4
           with:
              # The GitHub token
              repo-token: ${{secrets.WORKFLOW_TOKEN}}
              # Labels to add to an issue, seperated by commas.
              add-labels: "Slo validation Failed"
              # An issue number or PR number or project card number. Optional, if not specified, will use the one available in github event `github.event.pull_request` or `github.event.issue`
              issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}

         - name: Close Issue
           uses: peter-evans/close-issue@v2
           with:
              issue-number: ${{ needs.Open-Tracking-Issue.outputs.output1 }}
              comment: Auto-closing issue

  ## if validation fails Rollback to previous version
  ## Not best practive, best practice would be to use something like kubectl rollout undo daemonset <daemonset-name> --to-revision=<revision>
  ## In additon there would also be a rollback of the Master Branche    
  On-Fail-Rollback:
         runs-on: dynatracedemo
         needs: [Dynatrace-Slo-validation, Open-Tracking-Issue]
         if: "${{ needs.Dynatrace-Slo-validation.outputs.output1 < 90 }}"         
         steps:
         - name: On-Fail-Rollback
           env:
             builid: ${{ github.run_number }}
           run: |
              kubectl replace -f /home/ec2-user/rollback_prod.yaml --force
              kubectl wait --for=condition=available --timeout=120s --all deployments -A







          
    

  

